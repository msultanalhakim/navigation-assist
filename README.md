# 🦾 Object Detection for the Visually Impaired  

A real-time **YOLOv11-based object detection system** integrated into an **Android application** to assist visually impaired users in navigating their surroundings.  
The system detects key objects such as **doors, stairs, and obstacles**, and provides **audio feedback** to enhance user awareness and safety.  


## 🚀 Project Overview  
This project combines **computer vision** and **assistive technology** to empower individuals with visual impairments.  
By leveraging the YOLOv11 model, the system performs **fast and accurate object detection** in real time.  
The Android application connects with a TensorFlow Lite–optimized model to ensure smooth performance across different devices while maintaining high detection accuracy.  


## 🧠 Key Features  
- **Real-Time Detection** — Detects doors, stairs, people, and obstacles through the mobile camera.  
- **Audio Feedback System** — Converts detection results into spoken output to guide users.  
- **Mobile Optimization** — Ensures smooth operation on a wide range of Android devices.  
- **Accessible Design** — Simple interface with clear visual contrast and voice cues.  


## ⚙️ Tech Stack  
- **Model:** YOLOv11 (Ultralytics)  
- **Frameworks:** TensorFlow Lite, PyTorch  
- **Languages:** Python, Kotlin (Android)  
- **Tools:** OpenCV, Android Studio, Gradle  
- **Platform:** Android  


## 💡 Author  
**Muhammad Sultan Alhakim**  
Undergraduate Student, Informatics Engineering  
Jenderal Soedirman University  
📫 [LinkedIn](https://linkedin.com/in/msultanalhakim) | [GitHub](https://github.com/msultanalhakim)
